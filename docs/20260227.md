ã¨ã‚Šã‚ãˆãš
https://docs.langchain.com/oss/python/langchain/rag
ã®ç¶šãã‚’ã‚„ã‚‹ã“ã¨ã«ã™ã‚‹ã€‚
tool callingã‚’è¡Œã†RAGã¨ã‚‚ã†ä¸€ã¤ã€dynamic_promptã¨ã„ã†ã®ã‚‚ã‚ã‚‹ã‚‰ã—ã„ã€‚

```python
from langchain.agents.middleware import dynamic_prompt, ModelRequest

@dynamic_prompt
def prompt_with_context(request: ModelRequest) -> str:
    """Inject context into state messages."""
    last_query = request.state["messages"][-1].text
    retrieved_docs = vector_store.similarity_search(last_query)

    docs_content = "\n\n".join(doc.page_content for doc in retrieved_docs)

    system_message = (
        "You are a helpful assistant. Use the following context in your response:"
        f"\n\n{docs_content}"
    )

    return system_message


agent = create_agent(model, tools=[], middleware=[prompt_with_context])
```
ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çŠ¶æ³ã«å¿œã˜ã¦å¤‰æ›´ã—ãŸã‚Šã§ãã‚‹
ãŠã‚“ãªã˜ãƒ¦ãƒ¼ã‚¶ã¨AIãŒã‚¹ãƒ¬ãƒƒãƒ‰ã§é•·ãä¼šè©±ã¨ã‹ã™ã‚‹æ™‚ã«ã€ãƒ„ãƒ¼ãƒ«ã®æ¤œç´¢çµæœã¨ã‹ã‚’å…¥ã‚Œè¾¼ã‚ã°ä¼šè©±å±¥æ­´ãŒæ±šã‚Œãªã„ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ã«ãªã‚‹ã‹ã‚‚
```bash
================================ Human Message =================================

What is task decomposition?
{'messages': [HumanMessage(content='What is task decomposition?', additional_kwargs={}, response_metadata={}, id='f08a2810-1e17-47a1-a959-507f23e12c7d'), AIMessage(content='Task decomposition is a project management technique that involves breaking down a complex task or project into smaller, more manageable sub-tasks. By dividing a task into smaller components, it becomes easier to assign responsibilities, track progress, and ensure that all necessary steps are completed successfully. Task decomposition helps team members focus on specific elements of a task, improves efficiency, and reduces the risk of overlooking important details. This approach can also help in estimating timelines, setting priorities, and allocating resources effectively.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 30, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-DDpFnYspHmlCNzaONRlFEKgaaPf5n', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c9e9d-9bbe-7ad3-b587-6b4f746f0db5-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 30, 'output_tokens': 95, 'total_tokens': 125, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}
================================== Ai Message ==================================

Task decomposition is a project management technique that involves breaking down a complex task or project into smaller, more manageable sub-tasks. By dividing a task into smaller components, it becomes easier to assign responsibilities, track progress, and ensure that all necessary steps are completed successfully. Task decomposition helps team members focus on specific elements of a task, improves efficiency, and reduces the risk of overlooking important details. This approach can also help in estimating timelines, setting priorities, and allocating resources effectively.
```
å˜ç´”ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åŸ‹ã‚è¾¼ã‚€ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’å®šç¾©ã—ã¦ã„ã‚‹ã ã‘ã€‚ãªã‚“ã‹ä¾¿åˆ©ãã†ã€‚
ãã®ä¸‹ã«ã€AgentMiddleWareã‚’åˆ©ç”¨ã—ãŸRaw Dataã®ä¿å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ›¸ã„ã¦ã‚ã‚‹ã€‚

ä½¿ã£ã¦ã¿ãŸã¨ã“ã‚ã€
```python
å–å¾—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: 4

--- Document 1 ---
  metadata : {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}
  content  : Component One: Planning#
A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.
Task Decomposition#
Chain of thought (CoT; Wei et al. 2022) has become a s...

--- Document 2 ---
  metadata : {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}
  content  : Task decomposition can be done (1) by LLM with simple prompting like "Steps for XYZ.\n1.", "What are the subgoals for achieving XYZ?", (2) by using task-specific instructions; e.g. "Write a story outl...

--- Document 3 ---
  metadata : {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17734}
  content  : The AI assistant can parse user input to several tasks: [{"task": task, "id", task_id, "dep": dependency_task_ids, "args": {"text": text, "image": URL, "audio": URL, "video": URL}}]. The "dep" field d...

--- Document 4 ---
  metadata : {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19303}
  content  : (3) Task execution: Expert models execute on the specific tasks and log results.
Instruction:

With the input and the inference results, the AI assistant needs to describe the process and results. The...
```
ã¨ã„ã†æ„Ÿã˜ã§ã—ã£ã‹ã‚Šã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«æˆåŠŸã—ã¦ã„ã‚‹
dynamic_promptã‚‚
```python
@overload
def dynamic_prompt(
    func: _CallableReturningSystemMessage[StateT, ContextT],
) -> AgentMiddleware[StateT, ContextT]: ...
```
ã¨ã„ã†ä»•æ§˜ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€çµå±€ã®ã¨ã“ã‚AgentMiddleWareã‚¯ãƒ©ã‚¹ã‚’ä½¿ã†ã¨langchainã®ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’ã„ã˜ã‚Œãã†

```python
 middleware: A sequence of middleware instances to apply to the agent.

            Middleware can intercept and modify agent behavior at various stages.

            !!! tip ""

                See the [Middleware](https://docs.langchain.com/oss/python/langchain/middleware)
                docs for more information.
```
https://docs.langchain.com/oss/python/langchain/middleware/overview
ã«è‰²ã€…ãªè©³ç´°ã‚ã‚Š
![middlewareã®ä¸­èº«](image.png)
ã“ã‚“ãªæ„Ÿã˜ã§ã€toolã‚„resultã‚’å‘¼ã³å‡ºã™å‰å¾Œã«é–¢æ•°ã‚’ã‹ã¾ã™ã“ã¨ãŒã§ãã‚‹ã‚‰ã—ã„ã€‚
https://docs.langchain.com/oss/python/langchain/middleware/built-in

ã“ã®è¾ºã«ã„ã£ã±ã„ã‚ã‚‹ãª
Antigravityã ã¨ã‹Codexã®tool callæ™‚ã®æ‰¿èªæ©Ÿèƒ½ã¨ã‹ã¯HumanIntheLoopã¨ã‹ã‚’ä½¿ãˆã°åˆ©ç”¨ã§ãã‚‹ã‚ã‘ã ã­
å€‹äººæƒ…å ±ã®æ¤œå‡ºã¨ã‹ã‚‚ã‚ã‚‹ã—ã€ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¿½åŠ ã‚‚ã§ãã‚‹ã€‚

Streamã¯ä¸€æ—¦ç½®ã„ã¦ãŠã„ã¦ã€Short-term memoryã‚’ã‚„ã£ã¦ã¿ãŸã„
```python
from langchain.agents import create_agent, AgentState
from langgraph.checkpoint.memory import InMemorySaver


class CustomAgentState(AgentState):  
    user_id: str
    preferences: dict

agent = create_agent(
    "gpt-5",
    tools=[get_user_info],
    state_schema=CustomAgentState,  
    checkpointer=InMemorySaver(),
)

# Custom state can be passed in invoke
result = agent.invoke(
    {
        "messages": [{"role": "user", "content": "Hello"}],
        "user_id": "user_123",  
        "preferences": {"theme": "dark"}  
    },
    {"configurable": {"thread_id": "1"}})
```

çŸ­æœŸè¨˜æ†¶ã‚’å…¥ã‚Œã‚‹ã¨ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦ãŒãƒ‡ã‚«ããªã‚Šã™ãã‚‹ã®ã§ã€è‰²ã€…å¯¾ç­–ã™ã‚‹
```python
@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """Keep only the last few messages to fit context window."""
    messages = state["messages"]

    if len(messages) <= 3:
        return None  # No changes needed

    first_msg = messages[1]
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages

    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }
```
ã“ã‚Œã®before_modelã£ã¦ã„ã†ã®ã¯ã€ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®å›³ã®ã‚„ã¤ã®ã“ã¨ã ã¨æ€ã†
```bash
I donâ€™t know your nameâ€”you havenâ€™t told me yet. What would you like me to call you?
```
ã¡ã‚‡ã£ã¨ä¸­èº«ã‚’ã„ã˜ã£ã¦ã¿ãŸã‚‰ã€æ•™ãˆãŸã¯ãšã®åå‰ã‚’å¿˜ã‚ŒãŸã®ã§ã€ã†ã¾ãè¡Œã£ã¦ãã†ã€‚ä»Šã¾ã§ç›´æ¥æ³¨å…¥ã—ã¦ã„ãŸãŒã€ã“ã‚Œã‚’ä½¿ã£ãŸæ–¹ãŒç¶ºéº—ã«è‰²ã€…ç®¡ç†ã§ãã‚‹
è¦ç´„ã‚‚å¯èƒ½ã‚‰ã—ã„
```python
SummarizationMiddleware(
  self,
  model: str | BaseChatModel,
  *,
  trigger: ContextSize | list[ContextSize] | None = None,
  keep: ContextSize = ('messages', _DEFAULT_MESSAGES_TO_KEEP),
  token_counter: TokenCounter = count_tokens_approximately,
  summary_prompt: str = DEFAULT_SUMMARY_PROMPT,
  trim_tokens_to_summarize: int | None = _DEFAULT_TRIM_TOKEN_LIMIT,
  **deprecated_kwargs: Any = {}
)
```
ã»ã‚“ã¨ã«Summerizationã—ã¦ã‚‹ã‹çŸ¥ã‚ŠãŸã„ãª
```bash
--- Step 1 ---
(è¦ç´„ãªã—)

--- Step 2 ---
(è¦ç´„ãªã—)

--- Step 3 ã®è¦ç´„ ---
Here is a summary of the conversation to date:

## SESSION INTENT
The user introduced themselves and shared their interests.

## SUMMARY
The user greeted with "ã“ã‚“ã«ã¡ã¯" and shared their name as "å¤ªéƒ." They mentioned their hobbies: programming and mountain climbing.

## ARTIFACTS
None

## NEXT STEPS
Wait for the user's next input or request to continue assisting.

--- Step 4 ã®è¦ç´„ ---
Here is a summary of the conversation to date:

## SESSION INTENT
The userâ€™s primary goal is to learn detailed information about Python, specifically the mechanism and workings of decorators.

## SUMMARY
The user initially introduced themselves as "å¤ªéƒ" and shared interests in programming and mountain climbing. The conversation then shifted to a focused request where the user asked for a detailed explanation about Python, emphasizing understanding how decorators work. The assistant acknowledged the userâ€™s interests and prompted further discussion, and then the user clearly requested in Japanese to learn about Python decorators.

## ARTIFACTS
None

## NEXT STEPS
Provide a clear, detailed explanation of Python decorators including their purpose, how they are defined, how they modify functions, and examples of common use cases. Clarify any related concepts such as closures or higher-order functions if relevant.

--- Step 5 ã®è¦ç´„ ---
Here is a summary of the conversation to date:

## SESSION INTENT
The userâ€™s primary goal is to learn detailed information about Python concepts, focusing first on decorators and now requesting an explanation about Python generators including how they differ from iterators.

## SUMMARY
- The user initially asked for a detailed explanation about Python decorators.
- The assistant explained decorators thoroughly, including concepts such as:
  - Decorators as functions wrapping other functions.
  - Syntax using the @decorator notation.
  - Inner workings using closures and higher-order functions.
  - Examples with and without function arguments.
  - Mention of built-in decorators like @staticmethod, @classmethod, @property, and functools.wraps.
- The user expressed gratitude and then requested a detailed explanation of Python generators, including the difference between generators and iterators.

## ARTIFACTS
None

## NEXT STEPS
Provide a clear, detailed explanation of Python generators, how they work, including the `yield` keyword. Explain iterators as well, clarifying the differences and relationships between iterators and generators in Python, with examples for better understanding.
```
ã¡ã‚ƒã‚“ã¨è¦ç´„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚
```python
 for step, user_msg in enumerate(conversations, 1):
        agent.invoke({"messages": user_msg}, config)

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰è¦ç´„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã ã‘æŠ½å‡ºã—ã¦è¡¨ç¤º
        state = agent.get_state(config)
        messages = state.values.get("messages", [])
        summary = None
        for msg in messages:
            if "summary" in msg.content.lower():
                summary = msg.content
                break

        if summary:
            print(f"\n--- Step {step} ã®è¦ç´„ ---\n{summary}")
        else:
            print(f"\n--- Step {step} ---\n(è¦ç´„ãªã—)")
```
ã‚³ãƒ¼ãƒ‰ã¯ã“ã‚Œã€‚
çµå±€è«¸ã€…Dictå‹ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ã‚‰ã—ã„ã€‚
`test_summerization`ã®å®Ÿè£…ã ã¨ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚µã‚¤ã‚ºãŒ500ã«é”ã—ãŸæ™‚ç‚¹ã§è¦ç´„ã‚’å§‹ã‚ã‚‹ã‚‰ã—ã„ã€‚
```python
trigger: One or more thresholds that trigger summarization.

                Provide a single
                [`ContextSize`][langchain.agents.middleware.summarization.ContextSize]
                tuple or a list of tuples, in which case summarization runs when any
                threshold is met.

                !!! example

                    ```python
                    # Trigger summarization when 50 messages is reached
                    ("messages", 50)

                    # Trigger summarization when 3000 tokens is reached
                    ("tokens", 3000)

                    # Trigger summarization either when 80% of model's max input tokens
                    # is reached or when 100 messages is reached (whichever comes first)
                    [("fraction", 0.8), ("messages", 100)]
                    ```

                    See [`ContextSize`][langchain.agents.middleware.summarization.ContextSize]
                    for more details.
```
ãƒˆãƒªã‚¬ãƒ¼ã¯è¤‡æ•°è¨­å®šã™ã‚‹ã“ã¨ãŒå¯èƒ½ã€‚å¿…è¦ãªã®ã‹ãª...
çµå±€ã®ã¨ã“ã‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ç¯€ç´„ã™ã‚‹ãŸã‚ã®ä»•çµ„ã¿ã§ã€è¦ç´„ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸+ç›´å‰ã®ã„ãã¤ã‹ã®ä¼šè©±(keep)
ã‚’ä¿æŒã™ã‚‹ï¼Ÿ
```python
@override
    def before_model(
        self, state: AgentState[Any], runtime: Runtime[ContextT]
    ) -> dict[str, Any] | None:
        """Process messages before model invocation, potentially triggering summarization.

        Args:
            state: The agent state.
            runtime: The runtime environment.

        Returns:
            An updated state with summarized messages if summarization was performed.
        """
        messages = state["messages"]
        self._ensure_message_ids(messages)

        total_tokens = self.token_counter(messages)
        if not self._should_summarize(messages, total_tokens):
            return None

        cutoff_index = self._determine_cutoff_index(messages)

        if cutoff_index <= 0:
            return None

        messages_to_summarize, preserved_messages = self._partition_messages(messages, cutoff_index)

        summary = self._create_summary(messages_to_summarize)
        new_messages = self._build_new_messages(summary)

        return {
            "messages": [
                RemoveMessage(id=REMOVE_ALL_MESSAGES),
                *new_messages,
                *preserved_messages,
            ]
        }
```
`SummarizationMiddleware`ã‚‚çµå±€`AgentMiddleWare`ã®ç¶™æ‰¿ã‚¯ãƒ©ã‚¹ã§ã€`before_model`ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ãŸã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã€‚
ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è‡ªä½“ã‚’ä¸¸ã€…æ›¸ãæ›ãˆã‚‹æ„Ÿã˜ã§å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã€‚return Noneã£ã¦ä½•ã‚„ã­ã‚“ã£ã¦æ„Ÿã˜ã ãŒã€å°‘ãªãã¨ã‚‚ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã®æ–¹ã®before_modelã¯ã€NoneãŒè¿”å´ã•ã‚ŒãŸå ´åˆ no updateã¨ã„ã†æ„å‘³ã«ãªã‚‹ã‚‰ã—ã„ã®ã§ã€ã“ã‚Œã‚‚åŒæ§˜ã ã‚ã†ã¿ãŸã„ãª
ã¨ã“ã‚ã§ã€`InMemorySaver`ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã‹ã‚ˆãã‚ã‹ã‚“ãªã„ã€‚ã©ã†ã‚„ã‚‰`langgraph`ã®ãƒãƒ¼ãƒ‰ã¨ã—ã¦ç™»éŒ²ã•ã‚Œã‚‹ã¿ãŸã„ã ãŒ...
```python
# æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
    config = {"configurable": {"thread_id": thread_id}}
    latest = checkpointer.get(config)

    if latest is None:
        print("  (ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãªã—)")
        return

    print(f"\nğŸ“‹ æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:")
    print(f"  checkpoint_id : {latest['id']}")
    print(f"  channel_values keys: {list(latest['channel_values'].keys())}")

    # messages ã®ä¸­èº«ã‚’è¦‹ã‚‹
    messages = latest["channel_values"].get("messages", [])
    print(f"\nğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ ({len(messages)} ä»¶):")
    for i, msg in enumerate(messages):
        role = getattr(msg, "type", "unknown")
        content = getattr(msg, "content", str(msg))
        # tool ã®å ´åˆã¯çŸ­ç¸®
        preview = content[:120] + ("..." if len(content) > 120 else "")
        print(f"  [{i}] {role:>10}: {preview}")
```
ã“ã†ã„ã†æ„Ÿã˜ã§ã‚¹ãƒ¬ãƒƒãƒ‰IDã‚’å…ƒã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’å–å¾—ã§ããŸã€‚
```bash
ğŸ“‹ æœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:
  checkpoint_id : 1f113da3-4343-6572-8008-28491e4a8497
  channel_values keys: ['messages', 'user_id', 'preferences', '__pregel_tasks']

ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ (8 ä»¶):
  [0]      human: Hello, who am I?
  [1]         ai:
  [2]       tool: User is John Smith
  [3]         ai: Youâ€™re John Smith. If thatâ€™s not correct, let me know and I can update it.
  [4]      human: What theme do I prefer?
  [5]         ai:
  [6]       tool: User is John Smith
  [7]         ai: I donâ€™t have your theme preference on file. Do you mean a UI theme (light, dark, or system) or another kind of theme (e....

ğŸ·  user_id: user_123

ğŸ·  preferences: {'theme': 'dark'}
```
`checkpoint_id`ã¯æ¯å›å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€å‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®çŠ¶æ…‹ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã‹ã‚‚ã§ããã†


