from typing import Any

from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_core.documents import Document
from langchain_community.document_loaders import WebBaseLoader
import bs4
from src import fetch_docs, split_text, create_retrieve_context_tool,create_retrieve_context_with_dynamic_prompt
from langchain.agents import create_agent
from langchain.agents.middleware import AgentMiddleware, AgentState
from langchain_openai import ChatOpenAI
from langgraph.runtime import Runtime


load_dotenv()
def tool_rag():
    # Load the document
    docs = fetch_docs(["https://lilianweng.github.io/posts/2023-06-23-agent/"])
    chunks = split_text(docs)
    
    embedding = OpenAIEmbeddings()
    vector_store = InMemoryVectorStore(embedding=embedding)
    document_ids = vector_store.add_documents(chunks)
    
    retrieve_context = create_retrieve_context_tool(vector_store)
    tools = [retrieve_context]
    
    prompt = (
    "You have access to a tool that retrieves context from a blog post. "
    "Use the tool to help answer user queries."
    )
    agent = create_agent(model=ChatOpenAI(), tools=tools, system_prompt=prompt)

    query = "What is task decomposition?"
    for step in agent.stream(
        {"messages": [{"role": "user", "content": query}]},
        stream_mode="values",
    ):
        print(step)
        step["messages"][-1].pretty_print()

def dynamic_prompt_rag():
    # Load the document
    docs = fetch_docs(["https://lilianweng.github.io/posts/2023-06-23-agent/"])
    chunks = split_text(docs)
    
    embedding = OpenAIEmbeddings()
    vector_store = InMemoryVectorStore(embedding=embedding)
    
    prompt = "You are a helpful assistant. Use the following context in your response:"
    retrieve_context = create_retrieve_context_with_dynamic_prompt(vector_store,prompt)
    
    
    agent = create_agent(model=ChatOpenAI(), tools=[],middleware=[retrieve_context])

    query = "What is task decomposition?"
    for step in agent.stream(
        {"messages": [{"role": "user", "content": query}]},
        stream_mode="values",
    ):
        print(step)
        step["messages"][-1].pretty_print()


class State(AgentState):
    context: list[Document]


class RetrieveDocumentsMiddleware(AgentMiddleware[State]):
    state_schema = State

    def __init__(self, vector_store: InMemoryVectorStore):
        self.vector_store = vector_store

    def before_model(self, state: AgentState,runtime: Runtime[None]) -> dict[str, Any] | None:
        last_message = state["messages"][-1]
        retrieved_docs = self.vector_store.similarity_search(last_message.text)

        docs_content = "\n\n".join(doc.page_content for doc in retrieved_docs)

        augmented_message_content = (
            f"{last_message.text}\n\n"
            "Use the following context to answer the query:\n"
            f"{docs_content}"
        )
        return {
            "messages": [last_message.model_copy(update={"content": augmented_message_content})],
            "context": retrieved_docs,
        }


def agent_middleware_rag():
    """AgentMiddleware ã‚’ä½¿ã£ãŸ RAG ã®ãƒ†ã‚¹ãƒˆ"""
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ & åˆ†å‰²
    docs = fetch_docs(["https://lilianweng.github.io/posts/2023-06-23-agent/"])
    chunks = split_text(docs)

    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆ
    embedding = OpenAIEmbeddings()
    vector_store = InMemoryVectorStore(embedding=embedding)
    vector_store.add_documents(chunks)

    # ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã‚’ä½¿ã£ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    middleware = RetrieveDocumentsMiddleware(vector_store)
    agent = create_agent(
        model=ChatOpenAI(),
        tools=[],
        middleware=[middleware],
    )

    query = "What is task decomposition?"

    # stream ã§æœ€çµ‚ã‚¹ãƒ†ãƒ¼ãƒˆã‚’å–å¾—
    final_state = None
    for step in agent.stream(
        {"messages": [{"role": "user", "content": query}]},
        stream_mode="values",
    ):
        final_state = step
        step["messages"][-1].pretty_print()

    # ---- raw data ã®æ´»ç”¨ãƒ‡ãƒ¢ ----
    print("\n" + "=" * 60)
    print("ğŸ“¦ ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã•ã‚ŒãŸ raw documents (context)")
    print("=" * 60)

    raw_docs: list[Document] = final_state.get("context", [])
    print(f"\nå–å¾—ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(raw_docs)}\n")

    for i, doc in enumerate(raw_docs, 1):
        print(f"--- Document {i} ---")
        print(f"  metadata : {doc.metadata}")
        print(f"  content  : {doc.page_content[:200]}...")
        print()

    # ä¾‹: raw data ã‚’ä½¿ã£ãŸäºŒæ¬¡åŠ å·¥
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯è¦ç´„æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥ã£ã¦ã„ã‚‹ãŒã€
    # context ã«ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãã®ã¾ã¾æ®‹ã£ã¦ã„ã‚‹ã®ã§
    # ã‚½ãƒ¼ã‚¹ URL ã®ä¸€è¦§ã‚’å‡ºã—ãŸã‚Šã€åˆ¥ã®å‡¦ç†ã«å†åˆ©ç”¨ã§ãã‚‹
    print("=" * 60)
    print("ğŸ”— ã‚½ãƒ¼ã‚¹ä¸€è¦§ (metadata ã‹ã‚‰æŠ½å‡º)")
    print("=" * 60)
    sources = {doc.metadata.get("source", "unknown") for doc in raw_docs}
    for src in sources:
        print(f"  - {src}")


if __name__ == "__main__":
    agent_middleware_rag()
